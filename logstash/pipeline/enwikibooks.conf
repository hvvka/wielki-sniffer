# input {
#  stdin {
#    codec => multiline
#    {
#        pattern => "<page"
#        negate => true
#        what => "previous"
#        auto_flush_interval => 1
#    }
#    #sincedb_path => "/dev/null"
#  }
# }
input {
  file {
    path => "/mnt/enwikibooks-20200301-pages-articles.xml" # slashes because of [2020-03-16T20:54:18,339][TRACE][filewatch.discoverer     ][main] discover_files {"count"=>0}
    codec => multiline
    { 
      pattern => "<page"
      negate => true
      what => "previous"
      auto_flush_interval => 1
    }
    start_position => "beginning"
    #sincedb_path => "NUL"
    #ignore_older => 0 commented because of [2020-03-16T21:07:59,780][TRACE][filewatch.discoverer     ][main] Discoverer discover_files: C:/Users/pancz/Desktop/studia/SWI/Lista_3/plwikisource-20200301-pages-articles-multistream.xml: skipping because it was last modified more than 0.0 seconds ago
    file_chunk_size => 65000
  }
}
filter {
    xml {
        source => "message"
        target => "doc"
        id => "id"
        store_xml => false
        periodic_flush => true
        xpath => [ "(page/title/text())[1]", "title" ]
        xpath => [ "(page/id/text())[1]", "id" ]
        xpath => [ "page/revision/text", "text" ]
        xpath => [ "(page/revision/timestamp/text())[1]", "timestamp"]
        xpath => [ "(page/revision/contributor/username/text())[1]", "contributor_name"]
    }
    grok {
      # first image match
      match => { "text" => "\[\[Image:(?<first_image>.*?)(\|.*|)\]\]" }
    }
    mutate {
        remove_field => ['doc', 'path', 'host', 'message', 'tags']
        join => ["id", ""]
        join => ["title", ""]
        gsub => [
            "text", "https?[^\s]+|<text xml:space=\"preserve\">|</text>", " ",
            "text", "==See also==(.|\n)+|==References==(.|\n)+|==Further reading==(.|\n)+", " ",
            "text", "(\&lt;.+?\&gt;)", " ",
            "text", "(\/ref|\{\{[c|C]ite.+?\}\})", " ",
            "text", "[\[\[|\]\]|==|=|\(|\)|\{\{|\}\}|]|\#+|'+|\&amp;|\&lt;|\&gt;|&nbsp;", " ",
            "text", "\.", " . ",
            "text", "\,", " , ",
            "text", "\:", " : ",
            "text", "\;", " ; ",
            "text", "\/", " \/ ",
            "text", '"', ' " ',
            "text", " +", " ",
            "text", "\. (\. )+", ". ",
            "text", '\n *(\n| )*', ' <br> '
        ]
        join => ["timestamp", ""]
        join => ["contributor_name", ""]
    }
    date {
      match => ["timestamp", "yyyy-MM-dd'T'HH:mm:ssZ"]
    }
    # added categories
    grok {
      match => { "title" => "(%{GREEDYDATA:categories}/%{GREEDYDATA:title}|%{GREEDYDATA:title})"}
      overwrite => [ "title" ]
    }
    mutate {
      split => {"categories" => "/" }
    }
    # ==fist image==
    # first_image if really first:
    #(\[\[[Ii][Mm][Aa][Gg][Ee]:(?<first_image>.*?)(\|.*|)\]\])?(.|\r|\n)*
    #
    # first_image in whole txext:
    #.*?\[\[[Ii][Mm][Aa][Gg][Ee]:(?<first_image>.*?)(\|.*|)\]\](.|\r|\n)*
}
output {
   elasticsearch {
     hosts => "http://elasticsearch:9200"
     index => "enwikibooks"
     document_id => "%{id}"
  }
#stdout {} commented because of performance consderations
}
